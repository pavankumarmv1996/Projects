{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "**Problem Statement:** Company X owns a movie application and repository which caters movie streaming to millions of users who on subscription\n",
        "basis. Company wants to automate the process of cast and crew information in each scene from a movie such that when a user pauses on\n",
        "the movie and clicks on cast information button, the app will show details of the actor in the scene. Company has an in-house computer\n",
        "vision and multimedia experts who need to detect faces from screen shots from the movie scene.\n",
        "The data labelling is already done. Since there higher time complexity is involved in the"
      ],
      "metadata": {
        "id": "vLIjxuvq6W6V"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jzQLvIvu43eM"
      },
      "outputs": [],
      "source": [
        "#importing neccesary libraries\n",
        "import numpy as np\n",
        "import cv2\n",
        "from sklearn.model_selection import train_test_split\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.layers import Input, Conv2D, MaxPooling2D, UpSampling2D, concatenate\n",
        "from google.colab import drive"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "CzYok0BU6oI0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "file_path = '/content/drive/My Drive/images.npy'"
      ],
      "metadata": {
        "id": "PXwb0vgJAf-8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data = np.load(file_path, allow_pickle=True)"
      ],
      "metadata": {
        "id": "cse1wyrVA0w8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print('Shape of X_train: ', X_train.shape)\n",
        "print('Shape of mask array: ', masks.shape)"
      ],
      "metadata": {
        "id": "W1YLtZY1BNlh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data[70][1]"
      ],
      "metadata": {
        "id": "u1Iqqnei9Lnu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.applications.mobilenet import preprocess_input\n",
        "\n",
        "masks = np.zeros((int(data.shape[0]), 224, 224))\n",
        "X_train = np.zeros((int(data.shape[0]), 224, 224, 3))\n",
        "for index in range(data.shape[0]):\n",
        "    img = data[index][0]\n",
        "    img = cv2.resize(img, dsize = (224, 224), interpolation = cv2.INTER_CUBIC)\n",
        "    try:\n",
        "      img = img[:, :, :3]\n",
        "    except:\n",
        "      continue\n",
        "    X_train[index] = preprocess_input(np.array(img, dtype = np.float32))\n",
        "    for i in data[index][1]:\n",
        "        x1 = int(i[\"points\"][0]['x'] * 224)\n",
        "        x2 = int(i[\"points\"][1]['x'] * 224)\n",
        "        y1 = int(i[\"points\"][0]['y'] * 224)\n",
        "        y2 = int(i[\"points\"][1]['y'] * 224)\n",
        "        masks[index][y1:y2, x1:x2] = 1"
      ],
      "metadata": {
        "id": "_RhMgBaw2sel"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "n = 12\n",
        "print(X_train[n])\n",
        "plt.imshow(X_train[n])"
      ],
      "metadata": {
        "id": "BUQ71nS2E_qU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plt.imshow(masks[n])"
      ],
      "metadata": {
        "id": "WqhzDiPDFFQV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf"
      ],
      "metadata": {
        "id": "5tdwORhUxK-q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.applications import MobileNet"
      ],
      "metadata": {
        "id": "v33jzqHomohe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.layers import Conv2D, Reshape\n",
        "from tensorflow.keras.layers import Conv2D, UpSampling2D, concatenate\n",
        "from tensorflow.keras.layers import Concatenate, UpSampling2D"
      ],
      "metadata": {
        "id": "fHX29zawDohD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def create_model(trainable = True):\n",
        "    IMG_SHAPE = (224, 224, 3)\n",
        "    model = MobileNet(input_shape = IMG_SHAPE, alpha = 1.0, include_top = False, weights = 'imagenet')\n",
        "    for layer in model.layers:\n",
        "        layer.trainable = trainable\n",
        "\n",
        "    block0 = model.get_layer('conv_pw_1_relu').output\n",
        "    block1 = model.get_layer('conv_pw_3_relu').output\n",
        "    block2 = model.get_layer('conv_pw_5_relu').output\n",
        "    block3 = model.get_layer('conv_pw_11_relu').output\n",
        "    block4 = model.get_layer('conv_pw_13_relu').output\n",
        "\n",
        "    x = Concatenate()([UpSampling2D()(block4), block3])\n",
        "    x = Concatenate()([UpSampling2D()(x), block2])\n",
        "    x = Concatenate()([UpSampling2D()(x), block1])\n",
        "    x = Concatenate()([UpSampling2D()(x), block0])\n",
        "    x = UpSampling2D()(x)\n",
        "    x = Conv2D(1, kernel_size = 1, activation = \"sigmoid\")(x)\n",
        "\n",
        "    x = Reshape((224, 224))(x)\n",
        "\n",
        "    return Model(inputs = model.input, outputs = x)"
      ],
      "metadata": {
        "id": "4h8c-7GxFY15"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Give trainable=False as argument, if you want to freeze lower layers for fast training (but low accuracy)\n",
        "model = create_model()\n",
        "\n",
        "# Print summary\n",
        "model.summary()"
      ],
      "metadata": {
        "id": "NhQZoRuXFeh4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Design your own Dice Coefficient and Loss function:**"
      ],
      "metadata": {
        "id": "KgLHGo4o0QBy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.losses import binary_crossentropy\n",
        "from tensorflow.keras.backend import log, epsilon\n",
        "\n",
        "def dice_coefficient(y_true, y_pred):\n",
        "    numerator = 2 * tf.reduce_sum(y_true * y_pred)\n",
        "    denominator = tf.reduce_sum(y_true + y_pred)\n",
        "\n",
        "    return numerator / (denominator + tf.keras.backend.epsilon())"
      ],
      "metadata": {
        "id": "wOwmqJwGeVYi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def loss(y_true, y_pred):\n",
        "    return binary_crossentropy(y_true, y_pred) - log(dice_coefficient(y_true, y_pred) + tf.keras.backend.epsilon())"
      ],
      "metadata": {
        "id": "MmL3_GjQ0jEx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.optimizers import Adam\n",
        "optimizer = Adam(learning_rate=1e-4, beta_1=0.9, beta_2=0.999, epsilon=None, amsgrad=False)\n",
        "model.compile(loss=loss, optimizer=optimizer, metrics=[dice_coefficient])"
      ],
      "metadata": {
        "id": "L0FBikUA0nqg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.callbacks import ModelCheckpoint, EarlyStopping, ReduceLROnPlateau\n",
        "\n",
        "checkpoint = ModelCheckpoint(\"model-{loss:.2f}.h5\", monitor=\"loss\", verbose=1, save_best_only=True,\n",
        "                             save_weights_only=True, mode=\"min\", save_freq=1)\n",
        "stop = EarlyStopping(monitor=\"loss\", patience=5, mode=\"min\")\n",
        "reduce_lr = ReduceLROnPlateau(monitor=\"loss\", factor=0.2, patience=5, min_lr=1e-6, verbose=1, mode=\"min\")"
      ],
      "metadata": {
        "id": "s7tUunhIGWc8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.fit(X_train, masks, epochs = 10, batch_size = 1, validation_split = 0.1,  #splitting 10% of data into validation set\n",
        "                    callbacks = [checkpoint, reduce_lr, stop],\n",
        "                    workers = 8,\n",
        "                    use_multiprocessing = True,\n",
        "                    verbose = 1)"
      ],
      "metadata": {
        "id": "8ajoRaTn1Qjr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "n = 10\n",
        "sample_image = X_train[n]\n",
        "final_image = sample_image\n",
        "print(sample_image.shape)\n",
        "plt.imshow(sample_image)"
      ],
      "metadata": {
        "id": "1foZoqQ31W-4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Conclusion:**"
      ],
      "metadata": {
        "id": "_Wthzec4hUN2"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Project was all about how we can make use of a pretrained MobileNet (Transfer Learning) and on top of it add all the UNET layers to train, fit and evaluate model with an objective to predict the boundaries(mask) around the face in a given image.\n",
        "\n",
        "    Model was complied using binary cross entropy as loss, adam optimizer and dice coefficient as metrics.\n",
        "    \n",
        "    Model checkpoint, early stopping and learning rate reducers were used as callbacks.\n",
        "    Data was split into train and validation using 90/10 ratio. Best loss I got is 0.4323 and dice_coefficient of 0.7652 on the training data with just 10 epochs.\n",
        "    \n",
        "    Model weights for this were used and then used to predict on validation data to get mask.\n",
        "    \n",
        "    Further checked on sample image and imposed mask on the image.\n",
        "    As seen in the above images, it can be seen that model does a very good job in predicting the masks.\n"
      ],
      "metadata": {
        "id": "Mu5AmCXzheKT"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "upbLChuXhkmS"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}